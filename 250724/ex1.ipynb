{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "### - Given a text file of 10,000 lines, each line contains a pair of (key,value)\n",
    "### - Calculate the average value for each key\n",
    "### - Apply groupByKey() and reduceByKey() functions\n",
    "Compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text file with 10,000 lines of (key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 lines of key-value pairs in data/keyValue.txt\n"
     ]
    }
   ],
   "source": [
    "# generate a text file of 10,000 lines, each line contains a pair of (key, value) \n",
    "# where key is a random integer between 1 and 1000, and value is a random integer between 1 and 10000\n",
    "# the key-value pairs are separated by a tab character\n",
    "import random\n",
    "num_lines = 10000\n",
    "\n",
    "file_name = \"data/keyValue.txt\"\n",
    "with open(file_name, \"w+\") as f:\n",
    "    for i in range(num_lines):\n",
    "        key = random.randint(1, 1000)\n",
    "        value = random.randint(1, 10000)\n",
    "        f.write(f\"{key},{value}\\n\")\n",
    "\n",
    "print(f\"Generated {num_lines} lines of key-value pairs in {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a text file of 10,000 lines, each line contains a pair of (key, value) \n",
    "# where key is a random integer between 1 and 1000, and value is a random integer between 1 and 10000\n",
    "# the key-value pairs are separated by a tab character\n",
    "import random\n",
    "num_lines = 10000\n",
    "\n",
    "file_name = \"data/keyValuePairs.txt\"\n",
    "with open(file_name, \"w+\") as f:\n",
    "    for i in range(num_lines):\n",
    "        # key is random character between a and z\n",
    "        key = chr(random.randint(65,90))\n",
    "        value = random.randint(1, 10000)\n",
    "        f.write(f\"{key},{value}\\n\")\n",
    "\n",
    "print(f\"Generated {num_lines} lines of key-value pairs in {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Spark Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KeyValuePairs\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyValue_rdd = spark.sparkContext.textFile(\"data/keyValuePairs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E,453', 'T,3649', 'N,7835', 'O,3204', 'C,1891']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyValue_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse the pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = keyValue_rdd.map(lambda line: tuple(map(int, line.split(','))))\n",
    "pairs = keyValue_rdd.map(lambda line: (line.split(',')[0], int(line.split(',')[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('E', 453),\n",
       " ('T', 3649),\n",
       " ('N', 7835),\n",
       " ('O', 3204),\n",
       " ('C', 1891),\n",
       " ('D', 2149),\n",
       " ('V', 6004),\n",
       " ('K', 4950),\n",
       " ('A', 2381),\n",
       " ('I', 8167)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate average value for each key applying groupByKey() and reduceByKey() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', <pyspark.resultiterable.ResultIterable at 0x25f1bbc36a0>),\n",
       " ('O', <pyspark.resultiterable.ResultIterable at 0x25f0421ec40>),\n",
       " ('C', <pyspark.resultiterable.ResultIterable at 0x25f0421ea30>),\n",
       " ('K', <pyspark.resultiterable.ResultIterable at 0x25f0421edf0>),\n",
       " ('J', <pyspark.resultiterable.ResultIterable at 0x25f0421e2e0>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by key\n",
    "grouped = pairs.groupByKey()\n",
    "grouped.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages using groupByKey(): [('N', 5023.275462962963), ('O', 4956.304785894206), ('C', 4970.28493150685), ('K', 4884.73631840796), ('J', 5220.904891304348), ('S', 4663.287206266318), ('R', 5062.941025641026), ('L', 5016.019073569482), ('W', 4851.543080939948), ('E', 4717.466666666666), ('T', 5141.010610079576), ('D', 5068.779527559055), ('V', 4841.910447761194), ('A', 4693.275675675675), ('I', 5074.010075566751), ('B', 5099.991666666667), ('U', 5219.643835616438), ('F', 5018.796650717703), ('H', 4941.757746478873), ('Q', 4816.017676767677), ('Z', 4847.907928388747), ('M', 4901.10752688172), ('X', 4993.679045092838), ('Y', 5304.022842639594), ('G', 4902.5610972568575), ('P', 5159.91280653951)]\n"
     ]
    }
   ],
   "source": [
    "averages_groupByKey = grouped.mapValues(lambda values: sum(values) / len(values))\n",
    "\n",
    "# Collect and print the results\n",
    "averages_groupByKey_result = averages_groupByKey.collect()\n",
    "print(\"Averages using groupByKey():\", averages_groupByKey_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts using groupByKey(): [('N', 432), ('O', 397), ('C', 365), ('K', 402), ('J', 368), ('S', 383), ('R', 390), ('L', 367), ('W', 383), ('E', 390), ('T', 377), ('D', 381), ('V', 402), ('A', 370), ('I', 397), ('B', 360), ('U', 365), ('F', 418), ('H', 355), ('Q', 396), ('Z', 391), ('M', 372), ('X', 377), ('Y', 394), ('G', 401), ('P', 367)]\n",
      "Time taken by groupByKey(): 2.881922721862793 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start_time_groupByKey = time.time()\n",
    "\n",
    "# Group by key and count occurrences\n",
    "grouped_pairs = pairs.groupByKey()\n",
    "counts_groupByKey = grouped_pairs.mapValues(len)\n",
    "\n",
    "# Collect and print the results\n",
    "counts_groupByKey_result = counts_groupByKey.collect()\n",
    "end_time_groupByKey = time.time()\n",
    "\n",
    "print(\"Counts using groupByKey():\", counts_groupByKey_result)\n",
    "print(\"Time taken by groupByKey():\", end_time_groupByKey - start_time_groupByKey, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages using reduceByKey(): [('N', 5023.275462962963), ('O', 4956.304785894206), ('C', 4970.28493150685), ('K', 4884.73631840796), ('J', 5220.904891304348), ('S', 4663.287206266318), ('R', 5062.941025641026), ('L', 5016.019073569482), ('W', 4851.543080939948), ('E', 4717.466666666666), ('T', 5141.010610079576), ('D', 5068.779527559055), ('V', 4841.910447761194), ('A', 4693.275675675675), ('I', 5074.010075566751), ('B', 5099.991666666667), ('U', 5219.643835616438), ('F', 5018.796650717703), ('H', 4941.757746478873), ('Q', 4816.017676767677), ('Z', 4847.907928388747), ('M', 4901.10752688172), ('X', 4993.679045092838), ('Y', 5304.022842639594), ('G', 4902.5610972568575), ('P', 5159.91280653951)]\n"
     ]
    }
   ],
   "source": [
    "# Reduce by key\n",
    "sum_counts = pairs.mapValues(lambda x: (x, 1))\\\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "averages_reduceByKey = sum_counts.mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "averages_reduceByKey_result = averages_reduceByKey.collect()\n",
    "print(\"Averages using reduceByKey():\", averages_reduceByKey_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts using reduceByKey(): [('N', 432), ('O', 397), ('C', 365), ('K', 402), ('J', 368), ('S', 383), ('R', 390), ('L', 367), ('W', 383), ('E', 390), ('T', 377), ('D', 381), ('V', 402), ('A', 370), ('I', 397), ('B', 360), ('U', 365), ('F', 418), ('H', 355), ('Q', 396), ('Z', 391), ('M', 372), ('X', 377), ('Y', 394), ('G', 401), ('P', 367)]\n",
      "Time taken by reduceByKey(): 2.674659013748169 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start_time_reduceByKey = time.time()\n",
    "\n",
    "# Count occurrences using reduceByKey\n",
    "counts_reduceByKey = pairs.mapValues(lambda value: 1).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Collect and print the results\n",
    "counts_reduceByKey_result = counts_reduceByKey.collect()\n",
    "end_time_reduceByKey = time.time()\n",
    "\n",
    "print(\"Counts using reduceByKey():\", counts_reduceByKey_result)\n",
    "print(\"Time taken by reduceByKey():\", end_time_reduceByKey - start_time_reduceByKey, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are the same.\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "groupByKey_dict = dict(averages_groupByKey_result)\n",
    "reduceByKey_dict = dict(averages_reduceByKey_result)\n",
    "\n",
    "comparison = [(key, groupByKey_dict[key], reduceByKey_dict[key]) for key in groupByKey_dict if groupByKey_dict[key] != reduceByKey_dict[key]]\n",
    "\n",
    "if not comparison:\n",
    "    print(\"The results are the same.\")\n",
    "else:\n",
    "    print(\"Differences found:\", comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
